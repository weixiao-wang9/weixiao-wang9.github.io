{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Two-Tower Retrieval - Interactive Notebook\n",
    "\n",
    "> **Companion to**: 03-two-tower-retrieval.md\n",
    "> **Run time**: ~5 minutes\n",
    "\n",
    "This notebook implements the two-tower retrieval model from X's recommendation algorithm.\n",
    "\n",
    "**Key concepts covered:**\n",
    "- Two-stage design (user tower + candidate tower)\n",
    "- Signed action embeddings (2x-1 trick)\n",
    "- Retrieval via matmul + top-k\n",
    "- Asymmetric design rationale\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports + Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Configuration\n",
    "EMB_SIZE = 64\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_ACTIONS = 19\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 4\n",
    "KEY_SIZE = 16\n",
    "VOCAB_SIZE = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ActionEmbedding Module\n",
    "\n",
    "Converts multi-hot action vectors to embeddings using the 2x-1 signed trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Convert multi-hot action vectors to embeddings.\n",
    "    \n",
    "    Uses the '2x-1' trick: maps {0, 1} -> {-1, +1}\n",
    "    This allows the model to distinguish between \"not performed\" and \"performed\".\n",
    "    \n",
    "    From recsys_retrieval_model.py:161-184\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_actions: int, emb_size: int):\n",
    "        super().__init__()\n",
    "        self.num_actions = num_actions\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        # Action projection matrix: [num_actions, emb_size]\n",
    "        self.proj = nn.Linear(num_actions, emb_size, bias=False)\n",
    "    \n",
    "    def forward(self, actions: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            actions: [B, S, num_actions] multi-hot vector (0 or 1)\n",
    "        \n",
    "        Returns:\n",
    "            action_emb: [B, S, emb_size] action embeddings\n",
    "        \"\"\"\n",
    "        B, S, _ = actions.shape\n",
    "        \n",
    "        # Apply 2x-1 trick: {0, 1} -> {-1, +1}\n",
    "        actions_signed = (2 * actions - 1).float()  # [B, S, num_actions]\n",
    "        \n",
    "        # Project to embedding space\n",
    "        action_emb = self.proj(actions_signed)  # [B, S, emb_size]\n",
    "        \n",
    "        # Mask out invalid positions (all zeros = no actions)\n",
    "        valid_mask = (actions.sum(dim=-1, keepdim=True) > 0)  # [B, S, 1]\n",
    "        action_emb = action_emb * valid_mask\n",
    "        \n",
    "        return action_emb\n",
    "\n",
    "# Test\n",
    "print(\"Testing ActionEmbedding...\")\n",
    "action_emb_module = ActionEmbedding(NUM_ACTIONS, EMB_SIZE).to(device)\n",
    "\n",
    "# Create dummy action vectors\n",
    "actions = torch.randint(0, 2, (4, 10, NUM_ACTIONS)).float().to(device)\n",
    "print(f\"Actions shape: {actions.shape}\")  # [4, 10, 19]\n",
    "\n",
    "# Get embeddings\n",
    "emb = action_emb_module(actions)\n",
    "print(f\"Action embeddings shape: {emb.shape}\")  # [4, 10, 64]\n",
    "\n",
    "# Verify the 2x-1 trick\n",
    "print(f\"Sample actions[0,0]: {actions[0,0,:5].tolist()}\")\n",
    "print(f\"After 2x-1: {(2*actions[0,0,:5]-1).tolist()}\")\n",
    "print(f\"✓ ActionEmbedding works!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CandidateTower Module\n",
    "\n",
    "Projects post+author embeddings to a shared embedding space using an expand-compress MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateTower(nn.Module):\n",
    "    \"\"\"\n",
    "    Candidate tower that projects post+author embeddings to a shared embedding space.\n",
    "    \n",
    "    Architecture: Expand -> Compress (same as X's implementation)\n",
    "    - Flatten: [B, num_hashes, D] -> [B, num_hashes * D]\n",
    "    - Expand: [B, num_hashes * D] -> [B, emb_size * 2]  \n",
    "    - Compress: [B, emb_size * 2] -> [B, emb_size]\n",
    "    - L2 normalize\n",
    "    \n",
    "    From recsys_retrieval_model.py:47-99\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, emb_size: int, hidden_size: int = None):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size or emb_size * 2\n",
    "        \n",
    "        # Expand projection: [num_hashes * D] -> [2 * D]\n",
    "        self.expand = nn.Linear(emb_size, self.hidden_size, bias=False)\n",
    "        \n",
    "        # Compress projection: [2 * D] -> [D]\n",
    "        self.compress = nn.Linear(self.hidden_size, emb_size, bias=False)\n",
    "    \n",
    "    def forward(self, embeddings: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: [B, num_hashes, D] or [B, D] (flattened)\n",
    "        \n",
    "        Returns:\n",
    "            candidate_emb: [B, D] L2-normalized candidate embedding\n",
    "        \"\"\"\n",
    "        # Flatten if needed\n",
    "        if embeddings.dim() == 3:\n",
    "            B, num_hashes, D = embeddings.shape\n",
    "            x = embeddings.reshape(B, -1)  # [B, num_hashes * D]\n",
    "        else:\n",
    "            x = embeddings\n",
    "        \n",
    "        # Expand: [B, num_hashes * D] -> [B, 2 * D]\n",
    "        x = F.silu(self.expand(x))\n",
    "        \n",
    "        # Compress: [B, 2 * D] -> [B, D]\n",
    "        x = self.compress(x)\n",
    "        \n",
    "        # L2 normalize (cosine similarity requires unit vectors)\n",
    "        x = F.normalize(x, p=2, dim=-1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Test\n",
    "print(\"Testing CandidateTower...\")\n",
    "candidate_tower = CandidateTower(EMB_SIZE, HIDDEN_SIZE).to(device)\n",
    "\n",
    "# Create dummy embeddings (post + author concatenated)\n",
    "num_hashes = 4  # 2 post hashes + 2 author hashes\n",
    "post_author_emb = torch.randn(4, num_hashes, EMB_SIZE).to(device)\n",
    "print(f\"Input shape: {post_author_emb.shape}\")  # [4, 4, 64]\n",
    "\n",
    "# Get candidate embeddings\n",
    "cand_emb = candidate_tower(post_author_emb)\n",
    "print(f\"Candidate embedding shape: {cand_emb.shape}\")  # [4, 64]\n",
    "\n",
    "# Verify L2 normalization\n",
    "norms = torch.norm(cand_emb, dim=-1)\n",
    "print(f\"L2 norms (should be ~1.0): {norms.tolist()}\")\n",
    "print(f\"✓ CandidateTower works!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. UserTower Module\n",
    "\n",
    "Encodes user features + history using a transformer + mean pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserTower(nn.Module):\n",
    "    \"\"\"\n",
    "    User tower that encodes user features + history into a single representation.\n",
    "    \n",
    "    Architecture:\n",
    "    1. Embed user features (hash embeddings)\n",
    "    2. Embed history (4 ingredients per position)\n",
    "    3. Concatenate: [user] + [history]\n",
    "    4. Transformer encoder\n",
    "    5. Mean pool all positions\n",
    "    6. L2 normalize\n",
    "    \n",
    "    From recsys_retrieval_model.py:206-276\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 emb_size: int,\n",
    "                 num_actions: int,\n",
    "                 num_layers: int = NUM_LAYERS,\n",
    "                 num_heads: int = NUM_HEADS):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        # User embedding (hash-based)\n",
    "        self.user_emb = nn.Linear(emb_size, emb_size, bias=False)  # Simplified\n",
    "        \n",
    "        # Action embeddings\n",
    "        self.action_emb = ActionEmbedding(num_actions, emb_size)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_size,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=emb_size * 4,\n",
    "            activation='silu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "    \n",
    "    def forward(self,\n",
    "                user_embedding: torch.Tensor,\n",
    "                history_embeddings: torch.Tensor,\n",
    "                padding_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            user_embedding: [B, 1, D] user token\n",
    "            history_embeddings: [B, S, D] history sequence\n",
    "            padding_mask: [B, S] boolean mask (True = valid)\n",
    "        \n",
    "        Returns:\n",
    "            user_repr: [B, D] L2-normalized user representation\n",
    "        \"\"\"\n",
    "        B, S, D = history_embeddings.shape\n",
    "        \n",
    "        # Concatenate: [user] + [history]\n",
    "        # [B, 1, D] + [B, S, D] -> [B, 1+S, D]\n",
    "        sequence = torch.cat([user_embedding, history_embeddings], dim=1)\n",
    "        \n",
        "        # Create full padding mask (user token is always valid)\n",
    "        if padding_mask is not None:\n",
    "            user_valid = torch.ones(B, 1, dtype=torch.bool, device=padding_mask.device)\n",
    "            full_mask = torch.cat([user_valid, padding_mask], dim=1)  # [B, 1+S]\n",
    "        else:\n",
    "            full_mask = None\n",
    "        \n",
    "        # Transformer\n",
    "        if full_mask is not None:\n",
    "            # Convert bool mask to attention mask (True = ignore)\n",
    "            mask = ~full_mask\n",
    "            output = self.transformer(sequence, src_key_padding_mask=mask)\n",
    "        else:\n",
    "            output = self.transformer(sequence)\n",
    "        \n",
    "        # Mean pool all positions (user + history)\n",
    "        if full_mask is not None:\n",
    "            # Weight by validity\n",
    "            weights = full_mask.float()  # [B, 1+S]\n",
    "            weights = weights / (weights.sum(dim=-1, keepdim=True) + 1e-8)\n",
    "            user_repr = (output * weights.unsqueeze(-1)).sum(dim=1)  # [B, D]\n",
    "        else:\n",
    "            user_repr = output.mean(dim=1)  # [B, D]\n",
    "        \n",
    "        # L2 normalize\n",
    "        user_repr = F.normalize(user_repr, p=2, dim=-1)\n",
    "        \n",
    "        return user_repr\n",
    "\n",
    "# Test\n",
    "print(\"Testing UserTower...\")\n",
    "user_tower = UserTower(EMB_SIZE, NUM_ACTIONS, NUM_LAYERS, NUM_HEADS).to(device)\n",
    "\n",
    "# Create dummy inputs\n",
    "B, S = 4, 10\n",
    "user_embedding = torch.randn(B, 1, EMB_SIZE).to(device)\n",
    "history_embeddings = torch.randn(B, S, EMB_SIZE).to(device)\n",
    "padding_mask = torch.ones(B, S, dtype=torch.bool).to(device)\n",
    "padding_mask[:, S//2:] = False  # Second half is padding\n",
    "\n",
    "print(f\"User embedding: {user_embedding.shape}\")\n",
    "print(f\"History embeddings: {history_embeddings.shape}\")\n",
    "print(f\"Padding mask: {padding_mask.shape}\")\n",
    "\n",
    "# Forward pass\n",
    "user_repr = user_tower(user_embedding, history_embeddings, padding_mask)\n",
    "print(f\"User representation: {user_repr.shape}\")\n",
    "\n",
    "# Verify L2 normalization\n",
    "norms = torch.norm(user_repr, dim=-1)\n",
    "print(f\"L2 norms (should be ~1.0): {norms.tolist()}\")\n",
    "print(f\"✓ UserTower works!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TwoTowerRetrieval Module\n",
    "\n",
    "Combines both towers for retrieval: user embedding x candidate embedding -> top-k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerRetrieval(nn.Module):\n",
    "    \"\"\"\n",
    "    Two-tower retrieval model for candidate generation.\n",
    "    \n",
    "    Architecture:\n",
    "    - User Tower: Encodes user + history -> user_repr [B, D]\n",
    "    - Candidate Tower: Encodes candidates -> cand_repr [B, C, D]\n",
    "    - Retrieval: user_repr @ cand_repr.T -> similarity [B, C]\n",
    "    \n",
    "    Both towers output L2-normalized embeddings, so dot product = cosine similarity.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 hidden_size: int,\n",
    "                 num_actions: int,\n",
    "                 num_layers: int = NUM_LAYERS,\n",
    "                 num_heads: int = NUM_HEADS):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        self.candidate_tower = CandidateTower(emb_size, hidden_size)\n",
    "        self.user_tower = UserTower(emb_size, num_actions, num_layers, num_heads)\n",
    "    \n",
    "    def forward(self,\n",
    "                user_embedding: torch.Tensor,\n",
    "                history_embeddings: torch.Tensor,\n",
    "                padding_mask: torch.Tensor,\n",
    "                candidate_embeddings: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            user_embedding: [B, 1, D] user token\n",
    "            history_embeddings: [B, S, D] history sequence\n",
    "            padding_mask: [B, S] boolean mask (True = valid)\n",
    "            candidate_embeddings: [B, C, num_hashes, D] candidate embeddings\n",
    "        \n",
    "        Returns:\n",
    "            scores: [B, C] similarity scores (before softmax)\n",
    "        \"\"\"\n",
    "        # User tower -> user_repr [B, D]\n",
    "        user_repr = self.user_tower(user_embedding, history_embeddings, padding_mask)\n",
    "        \n",
    "        # Candidate tower -> cand_repr [B, C, D]\n",
    "        cand_repr = self.candidate_tower(candidate_embeddings)\n",
    "        \n",
    "        # Dot product similarity (both are L2-normalized)\n",
    "        # [B, D] @ [D, C] -> [B, C]  (but cand_repr is [B, C, D])\n",
    "        scores = torch.bmm(user_repr.unsqueeze(1), cand_repr.transpose(1, 2)).squeeze(1)\n",
    "        # Equivalent to: (user_repr * cand_repr).sum(dim=-1)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def retrieve_top_k(self,\n",
    "                       user_repr: torch.Tensor,\n",
    "                       corpus_embeddings: torch.Tensor,\n",
    "                       k: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Retrieve top-k candidates from a corpus.\n",
    "        \n",
    "        Args:\n",
    "            user_repr: [B, D] user representation\n",
    "            corpus_embeddings: [N, D] pre-computed candidate embeddings\n",
    "            k: number of candidates to retrieve\n",
    "        \n",
    "        Returns:\n",
    "            top_k_indices: [B, k] indices of top-k candidates\n",
    "            top_k_scores: [B, k] similarity scores\n",
    "        \"\"\"\n",
    "        # Compute similarity: [B, D] @ [N, D].T -> [B, N]\n",
    "        scores = torch.mm(user_repr, corpus_embeddings.T)\n",
    "        \n",
    "        # Top-k\n",
    "        top_k_scores, top_k_indices = torch.topk(scores, k, dim=-1)\n",
    "        \n",
    "        return top_k_indices, top_k_scores\n",
    "\n",
    "# Test\n",
    "print(\"Testing TwoTowerRetrieval...\")\n",
    "model = TwoTowerRetrieval(EMB_SIZE, HIDDEN_SIZE, NUM_ACTIONS, NUM_LAYERS, NUM_HEADS).to(device)\n",
    "\n",
    "# Create dummy data\n",
    "B, S, C = 4, 10, 20\n",
    "num_hashes = 4\n",
    "\n",
    "user_embedding = torch.randn(B, 1, EMB_SIZE).to(device)\n",
    "history_embeddings = torch.randn(B, S, EMB_SIZE).to(device)\n",
    "padding_mask = torch.ones(B, S, dtype=torch.bool).to(device)\n",
    "candidate_embeddings = torch.randn(B, C, num_hashes, EMB_SIZE).to(device)\n",
    "\n",
    "# Forward pass\n",
    "scores = model(user_embedding, history_embeddings, padding_mask, candidate_embeddings)\n",
    "print(f\"Scores shape: {scores.shape}\")  # [B, C]\n",
    "print(f\"Score range: [{scores.min():.3f}, {scores.max():.3f}]\")\n",
    "\n",
    "# Verify L2 normalization\n",
    "user_repr = model.user_tower(user_embedding, history_embeddings, padding_mask)\n",
    "cand_repr = model.candidate_tower(candidate_embeddings)\n",
    "user_norms = torch.norm(user_repr, dim=-1)\n",
    "cand_norms = torch.norm(cand_repr, dim=-1)\n",
    "print(f\"User repr norms: {user_norms.mean():.4f}\")\n",
    "print(f\"Candidate repr norms: {cand_norms.mean():.4f}\")\n",
    "print(f\"✓ TwoTowerRetrieval works!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Demo: Retrieval with Synthetic Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DEMO: Two-Tower Retrieval\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create model\n",
    "model = TwoTowerRetrieval(EMB_SIZE, HIDDEN_SIZE, NUM_ACTIONS, NUM_LAYERS, NUM_HEADS).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Create synthetic users\n",
    "B = 3  # 3 users\n",
    "user_embedding = torch.randn(B, 1, EMB_SIZE).to(device)\n",
    "history_embeddings = torch.randn(B, 10, EMB_SIZE).to(device)\n",
    "padding_mask = torch.ones(B, 10, dtype=torch.bool).to(device)\n",
    "\n",
    "# Create synthetic corpus\n",
    "N = 1000  # 1000 items in corpus\n",
    "corpus_embeddings = torch.randn(N, EMB_SIZE).to(device)\n",
    "corpus_embeddings = F.normalize(corpus_embeddings, p=2, dim=-1)  # L2 normalize\n",
    "\n",
    "# Get user representations\n",
    "user_repr = model.user_tower(user_embedding, history_embeddings, padding_mask)\n",
    "print(f\"\\n1. User representations: {user_repr.shape}\")\n",
    "print(f\"   L2 norms: {torch.norm(user_repr, dim=-1).tolist()}\")\n",
    "\n",
    "# Retrieve top-5 candidates for each user\n",
    "top_k_indices, top_k_scores = model.retrieve_top_k(user_repr, corpus_embeddings, k=5)\n",
    "\n",
    "print(f\"\\n2. Top-5 retrievals per user:\")\n",
    "for i in range(B):\n",
    "    print(f\"   User {i}: indices={top_k_indices[i].tolist()}\")\n",
    "    print(f\"            scores={top_k_scores[i].tolist()}\")\n",
    "\n",
    "# Verify that norms are ~1.0\n",
    "print(f\"\\n3. Norm verification:\")\n",
    "print(f\"   User repr norms: {torch.norm(user_repr, dim=-1)}\")\n",
    "print(f\"   Corpus norms: {torch.norm(corpus_embeddings, dim=-1)[:5].tolist()}\")\n",
    "\n",
    "# Visualization: retrieval scores distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i in range(B):\n",
    "    all_scores = torch.mm(user_repr[i:i+1], corpus_embeddings.T).squeeze()\n",
    "    axes[i].hist(all_scores.cpu().numpy(), bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[i].axvline(top_k_scores[i, 0].item(), color='red', linestyle='--', \n",
    "                    label=f'Top-1: {top_k_scores[i, 0]:.3f}')\n",
    "    axes[i].set_title(f'User {i}')\n",
    "    axes[i].set_xlabel('Similarity Score')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].legend()\n",
    "plt.suptitle('Retrieval Score Distributions (corpus of 1000 items)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Demo complete! Users retrieved relevant candidates from corpus.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've implemented the two-tower retrieval model from X's recommendation algorithm!\n",
    "\n",
    "**Key takeaways:**\n",
    "\n",
    "1. **Two-tower design**: User tower and candidate tower are completely separate\n",
    "   - Allows pre-computing candidate embeddings offline\n",
    "   - User tower runs online for each request\n",
    "\n",
    "2. **Asymmetric architecture**:\n",
    "   - User tower: Transformer (complex, learns user preferences)\n",
    "   - Candidate tower: Simple MLP (just projects embeddings)\n",
    "\n",
    "3. **Signed action embeddings**: 2x-1 trick distinguishes \"not performed\" from \"performed\"\n",
    "\n",
    "4. **Efficient retrieval**: Dot product + top-k enables billion-scale search with ANN\n",
    "\n",
    "5. **L2 normalization**: Both towers output unit vectors, so dot product = cosine similarity\n",
    "\n",
    "**Next up**: [Lecture 4 - Ranking Model](04-ranking-model.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
